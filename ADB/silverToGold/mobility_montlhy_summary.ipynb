{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47e7ad89-894d-45df-bd2d-e8cdb3f9cf06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    with cte as (\n",
    "        select \n",
    "            location,\n",
    "            year,\n",
    "            month,\n",
    "            round(avg(case when mobility_retail = 0 then null else mobility_retail end), 2) as avg_retail,\n",
    "            round(avg(case when mobility_grocery = 0 then null else mobility_grocery end), 2) as avg_grocery,\n",
    "            round(avg(case when mobility_workplace = 0 then null else mobility_workplace end), 2) as avg_workplace,\n",
    "            round(avg(case when mobility_home = 0 then null else mobility_home end), 2) as avg_home\n",
    "        from global_temp.covidcombined\n",
    "        group by location, year, month\n",
    "    )\n",
    "    \n",
    "    select *,\n",
    "        dense_rank() over (partition by location, year order by avg_workplace asc) as workplace_reduction_rank,\n",
    "        dense_rank() over (partition by location, year order by avg_home desc) as home_stay_rank\n",
    "    from cte\n",
    "    order by location, year, month\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e50fea-3931-4e30-8472-a7bd3dafcd1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2 = df.fillna({\n",
    "    \"avg_retail\": -1,\n",
    "    \"avg_grocery\": -1,\n",
    "    \"avg_workplace\": -1,\n",
    "    \"avg_home\": -1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "825987b5-960e-4a04-9a25-17d43fdc1267",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_2.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"year\", \"month\") \\\n",
    "    .save(\"/mnt/gold/monthly_mobility_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e83af5f-9161-4029-b9b3-96384db99de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.catalog.uncacheTable(\"global_temp.covidcombined\")\n",
    "spark.catalog.dropGlobalTempView(\"covidcombined\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "mobility_montlhy_summary",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
